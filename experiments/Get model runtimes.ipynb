{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums, sem\n",
    "import numpy as np\n",
    "from statannot import add_stat_annotation\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\"/analysis/fabiane/documents/publications/patch_individual_filter_layers/MIA_revision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'font.size':8,\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_runtime(filename):\n",
    "    all_runtime_lines = ! grep \"Total time elapsed:\" $filename\n",
    "    all_iter_lines = ! grep \"output_dir = \" $filename\n",
    "    times = []\n",
    "    iterations = []\n",
    "    \n",
    "    for runtime_line in all_runtime_lines:\n",
    "        time = 0        \n",
    "        # convert runtime\n",
    "        for idx, inner_line in enumerate(runtime_line.split(\":\")[1:4]):\n",
    "            inner_line = inner_line.strip().split(\"\\\\\")[0]\n",
    "            if idx == 0:\n",
    "                # remove time symbol and convert to seconds\n",
    "                time += int(inner_line.split(\"h\")[0]) * 3600\n",
    "            elif idx == 1:\n",
    "                # remove time symbol and convert to seconds\n",
    "                time += int(inner_line.split(\"m\")[0]) * 60\n",
    "            elif idx == 2:\n",
    "                # remove time symbol\n",
    "                time += int(inner_line.split(\"s\")[0])\n",
    "        times.append(time)\n",
    "        \n",
    "    # UKB baseline full set didn't finish reporting for the last of the 10 runs\n",
    "    # it finished running but did not print out its running time.\n",
    "    # Therefore, we ran the model again in a separate file for that run.\n",
    "    if len(times) == 9:\n",
    "        failed_time = 5 * 3600 + 42 * 60 + 49 # taken from individual run of final iteration\n",
    "        times.append(failed_time)\n",
    "\n",
    "    # convert iterations\n",
    "    assert(len(all_iter_lines) == 1)\n",
    "    iter_line = all_iter_lines[0].split(\"\\\"\")[2]\n",
    "    all_checkpoints = !ls -l $iter_line\n",
    "    for checkpoint in all_checkpoints:\n",
    "        if checkpoint.endswith(\"FINAL.h5\"):\n",
    "            iterations.append(int(checkpoint.split(\"_\")[-2]))\n",
    "\n",
    "    #assert(len(times) == 50 or len(times) == 10)\n",
    "    return times, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleanup script for old runs\n",
    "#!destination=\"/ritter/share/projects/Methods/Eitel_local_filter/experiments_submission/models/MS/full_set/10xrandom_splits/experiment_r3/backup\" find \"/ritter/share/projects/Methods/Eitel_local_filter/experiments_submission/models/MS/full_set/10xrandom_splits/experiment_r3/\" -type f -newermt \"2021-01-01 00:00\" -not -newermt \"2021-01-22 15:55\" -exec bash -c ' dirname=$(dirname {}); mkdir -p \"${destination}/${dirname}\"; echo ! mv {} ${destination}/${dirname}/' \\;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times, iterations = get_runtime(\"ADNI_experiment-20_percent-10xrandom_sampling-random_search-Copy1.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_list = {\n",
    "    \"ADNI_small\" : [\n",
    "            \"ADNI_baseline-20_percent-10xrandom_sampling-random_search.ipynb\",\n",
    "            \"ADNI_LiuPatches-20_percent-10xrandom_sampling_random_search.ipynb\",\n",
    "            \"ADNI_experiment-20_percent-10xrandom_sampling-random_search-Copy1.ipynb\"\n",
    "            \n",
    "        ],\n",
    "    \"UKB_small\" : [\n",
    "            \"UKB_sex_baseline-20_percent-10xrandom_sampling_random_search-Copy1.ipynb\",\n",
    "            \"UKB_sex_LiuPatches-20_percent-10xrandom_sampling_random_search.ipynb\",\n",
    "            \"UKB_sex_experiment-20_percent-10xrandom_sampling-random_search-Copy1.ipynb\"\n",
    "        ],\n",
    "    \"MS_small\" : [\n",
    "            \"MS_baseline-full_set-10xrandom_splits-random_search-Copy2.ipynb\",\n",
    "            \"MS_LiuPatches-full_set-10xrandom_splits.ipynb\",\n",
    "            \"MS_experiment-full_set-10xrandom_splits-random_search-Copy1.ipynb\"\n",
    "        ],\n",
    "    \"ADNI_big\" : [\n",
    "            \"ADNI_baseline-full_set-10xrandom_sampling-random_search.ipynb\",\n",
    "            \"ADNI_LiuPatches-full_set-10xrandom_sampling.ipynb\",\n",
    "            \"ADNI_experiment-full_set-10xrandom_sampling-random_search.ipynb\"\n",
    "        ],\n",
    "    \n",
    "    \"UKB_big\" : [\n",
    "            \"UKB_sex_baseline-full_set-10xrandom_sampling-random_search-Copy1.ipynb\",\n",
    "            \"UKB_sex_LiuPatches-full_set-10xrandom_sampling_random_search.ipynb\",\n",
    "            \"UKB_sex_experiment-full_set-10xrandom_sampling-random_search-Copy1.ipynb\"\n",
    "        ],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fig = plt.Figure()\\naxs = []\\nfor i, experiment in enumerate(filename_list):\\n    print(experiment)\\n    time_base, iter_base = get_runtime(filename_list[experiment][0])\\n    time_pif, iter_pif = get_runtime(filename_list[experiment][1])\\n    # run statistical test\\n    test_time = ranksums(time_base, time_pif)\\n    test_iter = ranksums(iter_base, iter_pif)\\n    print(f\"Avg time baseline in seconds: {np.mean(time_base)}\")\\n    print(f\"Avg time PIF in seconds: {np.mean(time_pif)}\")\\n    print(test_time)\\n    print(f\"Avg number of iterations baseline: {np.mean(iter_base)}\")\\n    print(f\"Avg number of iterations PIF: {np.mean(iter_pif)}\")\\n    print(test_iter)\\n    \\n    # plot results\\n    i *= 3\\n    ax = plt.bar([i, i+1],\\n                 [np.mean(time_base), np.mean(time_pif)],\\n                 color=[\"tab:blue\", \"tab:orange\"],\\n                 label=[\"Baseline\", \"PIF\"])\\n    axs.append(ax)\\n    plt.errorbar(x=[i, i+1], \\n                 y=[np.mean(time_base), np.mean(time_pif)], \\n                 yerr=[sem(time_base), sem(time_pif)], \\n                 color=\"black\",\\n                 ls=\"none\",\\n                 label=\"_Errorbar\")\\n    \\n    x1, x2 = i, i+1\\n    y, h, col = np.max(time_base) + 70, 2, \\'k\\'\\n    #plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\\n    if test_time.pvalue < 0.05:\\n        plt.text((x1+x2)*.5, y+h, \"*\", ha=\\'center\\', va=\\'bottom\\', color=col)\\n    #else:\\n    #    plt.text((x1+x2)*.5, y+h, \"ns\", ha=\\'center\\', va=\\'bottom\\', color=col)\\n\\nleg = plt.legend(axs, [\"Baseline\", \"PIF\"])\\nleg.legendHandles[0].set_color(\\'tab:blue\\')\\nleg.legendHandles[1].set_color(\\'tab:orange\\')\\nplt.xticks(np.arange(0.5, 13, step=3), [\"ADNI small\", \"ADNI big\", \"UKB small\", \"UKB big\", \"VIMS\"])\\nplt.ylabel(\"Seconds\")\\nplt.title(\"Runtime in seconds\")\\nplt.show()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"fig = plt.Figure()\n",
    "axs = []\n",
    "for i, experiment in enumerate(filename_list):\n",
    "    print(experiment)\n",
    "    time_base, iter_base = get_runtime(filename_list[experiment][0])\n",
    "    time_pif, iter_pif = get_runtime(filename_list[experiment][1])\n",
    "    # run statistical test\n",
    "    test_time = ranksums(time_base, time_pif)\n",
    "    test_iter = ranksums(iter_base, iter_pif)\n",
    "    print(f\"Avg time baseline in seconds: {np.mean(time_base)}\")\n",
    "    print(f\"Avg time PIF in seconds: {np.mean(time_pif)}\")\n",
    "    print(test_time)\n",
    "    print(f\"Avg number of iterations baseline: {np.mean(iter_base)}\")\n",
    "    print(f\"Avg number of iterations PIF: {np.mean(iter_pif)}\")\n",
    "    print(test_iter)\n",
    "    \n",
    "    # plot results\n",
    "    i *= 3\n",
    "    ax = plt.bar([i, i+1],\n",
    "                 [np.mean(time_base), np.mean(time_pif)],\n",
    "                 color=[\"tab:blue\", \"tab:orange\"],\n",
    "                 label=[\"Baseline\", \"PIF\"])\n",
    "    axs.append(ax)\n",
    "    plt.errorbar(x=[i, i+1], \n",
    "                 y=[np.mean(time_base), np.mean(time_pif)], \n",
    "                 yerr=[sem(time_base), sem(time_pif)], \n",
    "                 color=\"black\",\n",
    "                 ls=\"none\",\n",
    "                 label=\"_Errorbar\")\n",
    "    \n",
    "    x1, x2 = i, i+1\n",
    "    y, h, col = np.max(time_base) + 70, 2, 'k'\n",
    "    #plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    if test_time.pvalue < 0.05:\n",
    "        plt.text((x1+x2)*.5, y+h, \"*\", ha='center', va='bottom', color=col)\n",
    "    #else:\n",
    "    #    plt.text((x1+x2)*.5, y+h, \"ns\", ha='center', va='bottom', color=col)\n",
    "\n",
    "leg = plt.legend(axs, [\"Baseline\", \"PIF\"])\n",
    "leg.legendHandles[0].set_color('tab:blue')\n",
    "leg.legendHandles[1].set_color('tab:orange')\n",
    "plt.xticks(np.arange(0.5, 13, step=3), [\"ADNI small\", \"ADNI big\", \"UKB small\", \"UKB big\", \"VIMS\"])\n",
    "plt.ylabel(\"Seconds\")\n",
    "plt.title(\"Runtime in seconds\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADNI_small\n",
      "Avg time baseline in seconds: 511.42\n",
      "Avg time patch-based in seconds: 554.28\n",
      "Avg time PIF in seconds: 369.16\n",
      "Test time base vs patch  RanksumsResult(statistic=-1.5304280123514791, pvalue=0.12591081960766878)\n",
      "Test time base vs pif  RanksumsResult(statistic=4.2879559625343244, pvalue=1.8032483134953376e-05)\n",
      "Test time patch vs pif  RanksumsResult(statistic=6.8938198754571127, pvalue=5.4313789912691996e-12)\n",
      "Avg number of iterations baseline: 100.16\n",
      "Avg number of iterations patch-based: 175.74\n",
      "Avg number of iterations PIF: 78.76\n",
      "Test iter base vs patch  RanksumsResult(statistic=-7.8658484778965656, pvalue=3.6660406342101307e-15)\n",
      "Test iter base vs pif  RanksumsResult(statistic=2.9298734470692729, pvalue=0.003391000757993385)\n",
      "Test iter patch vs pif  RanksumsResult(statistic=8.1105790834752938, pvalue=5.0379086455673431e-16)\n",
      "UKB_small\n",
      "Avg time baseline in seconds: 5397.66\n",
      "Avg time patch-based in seconds: 8297.1\n",
      "Avg time PIF in seconds: 4103.74\n",
      "Test time base vs patch  RanksumsResult(statistic=-8.0864507139111925, pvalue=6.142855827671919e-16)\n",
      "Test time base vs pif  RanksumsResult(statistic=3.4400161178530992, pvalue=0.00058167954468781014)\n",
      "Test time patch vs pif  RanksumsResult(statistic=8.410460248057678, pvalue=4.0840496460057363e-17)\n",
      "Avg number of iterations baseline: 138.94\n",
      "Avg number of iterations patch-based: 186.54\n",
      "Avg number of iterations PIF: 108.12\n",
      "Test iter base vs patch  RanksumsResult(statistic=-5.6081224686843614, pvalue=2.0453328069596184e-08)\n",
      "Test iter base vs pif  RanksumsResult(statistic=3.2159669719007433, pvalue=0.0013000579336389243)\n",
      "Test iter patch vs pif  RanksumsResult(statistic=6.5250005121201573, pvalue=6.8001301817872665e-11)\n",
      "MS_small\n",
      "Avg time baseline in seconds: 260.9\n",
      "Avg time patch-based in seconds: 360.76\n",
      "Avg time PIF in seconds: 226.54\n",
      "Test time base vs patch  RanksumsResult(statistic=-5.7115297668162182, pvalue=1.1196510781442768e-08)\n",
      "Test time base vs pif  RanksumsResult(statistic=1.6200476707324216, pvalue=0.1052220370513733)\n",
      "Test time patch vs pif  RanksumsResult(statistic=7.3315774375486393, pvalue=2.2745932918706556e-13)\n",
      "Avg number of iterations baseline: 86.74\n",
      "Avg number of iterations patch-based: 162.765625\n",
      "Avg number of iterations PIF: 74.54\n",
      "Test iter base vs patch  RanksumsResult(statistic=-7.6662152316681578, pvalue=1.7714583541820794e-14)\n",
      "Test iter base vs pif  RanksumsResult(statistic=1.2270999378313661, pvalue=0.21978503123823834)\n",
      "Test iter patch vs pif  RanksumsResult(statistic=8.5170651903411976, pvalue=1.6364739171655795e-17)\n",
      "ADNI_big\n",
      "Avg time baseline in seconds: 633.14\n",
      "Avg time patch-based in seconds: 1952.12\n",
      "Avg time PIF in seconds: 487.28\n",
      "Test time base vs patch  RanksumsResult(statistic=-8.6172748443213916, pvalue=6.8566414474756441e-18)\n",
      "Test time base vs pif  RanksumsResult(statistic=4.4671952792962095, pvalue=7.9251781021334182e-06)\n",
      "Test time patch vs pif  RanksumsResult(statistic=8.6172748443213916, pvalue=6.8566414474756441e-18)\n",
      "Avg number of iterations baseline: 48.9\n",
      "Avg number of iterations patch-based: 180.20560747663552\n",
      "Avg number of iterations PIF: 32.16\n",
      "Test iter base vs patch  RanksumsResult(statistic=-10.078803425060569, pvalue=6.855588242296088e-24)\n",
      "Test iter base vs pif  RanksumsResult(statistic=5.5702064593693468, pvalue=2.544376505573105e-08)\n",
      "Test iter patch vs pif  RanksumsResult(statistic=10.078803425060569, pvalue=6.855588242296088e-24)\n",
      "UKB_big\n",
      "Avg time baseline in seconds: 20557.2\n",
      "Avg time patch-based in seconds: 19034.4\n",
      "Avg time PIF in seconds: 15331.8\n",
      "Test time base vs patch  RanksumsResult(statistic=0.60474315681476354, pvalue=0.54534966801112361)\n",
      "Test time base vs pif  RanksumsResult(statistic=1.360672102833218, pvalue=0.17361733442494354)\n",
      "Test time patch vs pif  RanksumsResult(statistic=2.1166010488516727, pvalue=0.034293721036492766)\n",
      "Avg number of iterations baseline: 114.0\n",
      "Avg number of iterations patch-based: 155.6\n",
      "Avg number of iterations PIF: 86.7\n",
      "Test iter base vs patch  RanksumsResult(statistic=-2.4945655218609, pvalue=0.012611144099313947)\n",
      "Test iter base vs pif  RanksumsResult(statistic=1.2094863136295271, pvalue=0.22647606604348625)\n",
      "Test iter patch vs pif  RanksumsResult(statistic=3.2504944678793541, pvalue=0.0011520450981421845)\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "fig.set_size_inches(w=6.1, h=3.1)\n",
    "\n",
    "def inc_y(y):\n",
    "    if y > 1000:\n",
    "        y += 2500\n",
    "    else:\n",
    "        y += 23\n",
    "    return y\n",
    "\n",
    "def sub_plot(i, ax, base_data, patch_data, pif_data, test_base_patch, test_base_pif, test_patch_pif):\n",
    "    i *= 4\n",
    "    ax.bar([i, i+1, i+2],\n",
    "                 [np.mean(base_data), np.mean(patch_data), np.mean(pif_data)],\n",
    "                 color=[\"tab:gray\", \"tab:blue\", \"tab:orange\"],\n",
    "          ) #label=[\"Baseline\", \"PIF\"])\n",
    "\n",
    "    ax.errorbar(x=[i, i+1, i+2], \n",
    "                 y=[np.mean(base_data), np.mean(patch_data), np.mean(pif_data)], \n",
    "                 yerr=[sem(base_data), sem(patch_data), sem(pif_data)], \n",
    "                 color=\"black\",\n",
    "                 ls=\"none\")\n",
    "    \n",
    "    # define coords for significance labels\n",
    "    y, col = np.mean(patch_data), 'k'\n",
    "    if y > 360:\n",
    "        y += 800\n",
    "        h = 500\n",
    "    else:\n",
    "        y += 5\n",
    "        h = 2\n",
    "    \n",
    "    # test between baseline and patch based\n",
    "    x1, x2 = i, i+1\n",
    "    if test_base_patch.pvalue < 0.001:\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"**\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    elif test_base_patch.pvalue < 0.01:\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"*\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    \n",
    "    # test between baseline and PIF\n",
    "    x1, x2 = i, i+2\n",
    "    if test_base_pif.pvalue < 0.001:\n",
    "        y = inc_y(y)\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"**\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    elif test_base_pif.pvalue < 0.01:\n",
    "        y = inc_y(y)\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"*\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "        \n",
    "    # test between patch-based and PIF\n",
    "    x1, x2 = i+1, i+2\n",
    "    if test_patch_pif.pvalue < 0.001:\n",
    "        y = inc_y(y)\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"**\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    elif test_patch_pif.pvalue < 0.05:\n",
    "        y = inc_y(y)\n",
    "        ax.text((x1+x2)*.5, y+h/2, \"*\", ha='center', va='bottom', color=col)\n",
    "        ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "        \n",
    "\n",
    "for i, experiment in enumerate(filename_list):\n",
    "    print(experiment)\n",
    "    time_base, iter_base = get_runtime(filename_list[experiment][0])\n",
    "    time_patch, iter_patch = get_runtime(filename_list[experiment][1])\n",
    "    time_pif, iter_pif = get_runtime(filename_list[experiment][2])\n",
    "    # run statistical test\n",
    "    test_time_base_pif = ranksums(time_base, time_pif)\n",
    "    test_time_base_patch = ranksums(time_base, time_patch)\n",
    "    test_time_patch_pif = ranksums(time_patch, time_pif)\n",
    "    test_iter_base_pif = ranksums(iter_base, iter_pif)\n",
    "    test_iter_base_patch = ranksums(iter_base, iter_patch)\n",
    "    test_iter_patch_pif = ranksums(iter_patch, iter_pif)\n",
    "    print(f\"Avg time baseline in seconds: {np.mean(time_base)}\")\n",
    "    print(f\"Avg time patch-based in seconds: {np.mean(time_patch)}\")\n",
    "    print(f\"Avg time PIF in seconds: {np.mean(time_pif)}\")\n",
    "    print(\"Test time base vs patch \", test_time_base_patch)\n",
    "    print(\"Test time base vs pif \", test_time_base_pif)\n",
    "    print(\"Test time patch vs pif \", test_time_patch_pif)\n",
    "    print(f\"Avg number of iterations baseline: {np.mean(iter_base)}\")\n",
    "    print(f\"Avg number of iterations patch-based: {np.mean(iter_patch)}\")\n",
    "    print(f\"Avg number of iterations PIF: {np.mean(iter_pif)}\")\n",
    "    print(\"Test iter base vs patch \", test_iter_base_patch)\n",
    "    print(\"Test iter base vs pif \", test_iter_base_pif)\n",
    "    print(\"Test iter patch vs pif \", test_iter_patch_pif)\n",
    "    \n",
    "    # plot run time results\n",
    "    sub_plot(i, axes[0], time_base, time_patch, time_pif, test_time_base_patch, test_time_base_pif, test_time_patch_pif)\n",
    "        \n",
    "    # plot training iters results\n",
    "    sub_plot(i, axes[1], iter_base, iter_patch, iter_pif, test_iter_base_patch, test_iter_base_pif, test_iter_patch_pif)\n",
    "    \n",
    "    \n",
    "    for ax_idx, ax in enumerate(axes):\n",
    "        ax.set_xticks(np.arange(1, 20, step=4))\n",
    "        #ax.set_xticklabels([\"ADNI small\", \"ADNI big\", \"UKB small\", \"UKB big\", \"VIMS\"], rotation=45)\n",
    "        ax.set_xticklabels([\"ADNI\", \"UKB\", \"VIMS\", \"ADNI\",  \"UKB\"], rotation=45)\n",
    "        ax.annotate('Small', (0.22,0), (0, -42), color=\"gray\", xycoords='axes fraction', textcoords='offset points', va='top') \n",
    "        ax.annotate('Big', (0.74,0), (0, -42), color=\"gray\", xycoords='axes fraction', textcoords='offset points', va='top') \n",
    "        trans = ax.get_xaxis_transform()\n",
    "        \n",
    "        #ax.annotate('Big', (0.7,0), (0, -30), xycoords=trans, textcoords='offset points', ha='center', va='top') \n",
    "        #ax.annotate('Neonatal', xy=(1, -.1), xycoords=trans, ha=\"center\", va=\"top\")\n",
    "        ax.plot([-.4,-.4,10,10],[-.20,-.20-0.03,-.20-0.03,-.20], color=\"gray\", transform=trans, clip_on=False) # line small\n",
    "        ax.plot([12,12,19,19],[-.20,-.20-0.03,-.20-0.03,-.20], color=\"gray\", transform=trans, clip_on=False) # line big\n",
    "        if ax_idx == 0:\n",
    "            ax.set_ylabel(\"Seconds\")\n",
    "            ax.set_title(\"Run time in seconds\")\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            leg = ax.legend([\"Baseline\", \"Patch-based\", \"PIF\"])\n",
    "            leg.legendHandles[0] = matplotlib.patches.Rectangle(xy=(-0, -0), width=20, height=7, angle=0)\n",
    "            leg.legendHandles[0].set_color('tab:gray')\n",
    "            leg.legendHandles[1] = matplotlib.patches.Rectangle(xy=(-0, -0), width=20, height=7, angle=0)\n",
    "            leg.legendHandles[1].set_color('tab:blue')\n",
    "            leg.legendHandles[2] = matplotlib.patches.Rectangle(xy=(-0, -0), width=20, height=7, angle=0)\n",
    "            leg.legendHandles[2].set_color('tab:orange')\n",
    "            ax.legend(leg.legendHandles, [\"Baseline\", \"Patch-based\", \"PIF\"], loc=\"upper left\")            \n",
    "        else:\n",
    "            ax.set_ylabel(\"Iterations\")\n",
    "            ax.set_title(\"Number of iterations\")\n",
    "    \n",
    "    \n",
    "#leg = plt.legend(axes, [\"Baseline\", \"PIF\"])\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "fig.savefig(os.path.join(save_dir, \"Training_speed_comparison.pgf\"), bbox_inches='tight', dpi=250)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mort1)",
   "language": "python",
   "name": "mort1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
