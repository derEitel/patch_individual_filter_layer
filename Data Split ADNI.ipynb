{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for splitting the data set into separate train, validation and test sets. We create 10 random splits by sampling from the whole data set anew. For this we store a range of random states (20-30) which we can re-use to get the same splittings elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "import h5py\n",
    "\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "sys.path.insert(0,\"/analysis/fabiane/phd/nitorch/\")\n",
    "from nitorch.data import load_nifti\n",
    "from tabulate import tabulate\n",
    "from data_split import print_df_stats, create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# main configurations\n",
    "settings = {\n",
    "    \"data_path\": \"/ritter/share/projects/Methods/LRP/data/rieke-copy1/2Node_trial0/beta0/\",\n",
    "    \"ADNI_DIR\": \"/ritter/share/data/ADNI/ADNI_2Yr/ADNI_2Yr_15T_quick_preprocessed/\",\n",
    "    \"train_h5\": \"/ritter/share/data/ADNI_HDF5/Splits_Eitel/10xrandom_splits/train_AD_CN_2Yr15T_plus_UniqueScreening_quickprep_(96, 114, 96)_random_state\",\n",
    "    \"val_h5\": \"/ritter/share/data/ADNI_HDF5/Splits_Eitel/10xrandom_splits/val_AD_CN_2Yr15T_plus_UniqueScreening_quickprep_(96, 114, 96)_random_state\",\n",
    "    \"holdout_h5\": \"/ritter/share/data/ADNI_HDF5/Splits_Eitel/10xrandom_splits/holdout_AD_CN_2Yr15T_plus_UniqueScreening_quickprep_(96, 114, 96)_random_state\",\n",
    "    \"binary_brain_mask\": \"binary_brain_mask.nii.gz\",\n",
    "    \"data_table\" : \"/analysis/fabiane/other_code/johannes/cnn-interpretability/data/ADNI/ADNI_tables/customized/DxByImgClean_CompleteAnnual2YearVisitList_1_5T.csv\",\n",
    "    \"z_factor\" : 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data sets to disk?\n",
    "save = True\n",
    "\n",
    "# Binary brain mask used to cut out the skull.\n",
    "mask = load_nifti(settings[\"binary_brain_mask\"])\n",
    "\n",
    "# set random state seed\n",
    "random_states = np.arange(20, 30) # original is 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the table\n",
    "df = pd.read_csv(settings[\"data_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sometimes pre-processing fails and we removed\n",
    "# failed pre-processing in 067_S_0077/Screening \n",
    "\n",
    "failed_idx = list(df.loc[(df[\"PTID\"]==\"067_S_0077\") & (df[\"Visit\"] == \"Screening\")].index)\n",
    "df = df.drop(index=failed_idx)\n",
    "\n",
    "# remove all MCI subjects\n",
    "df = df[df['DX'] != 'MCI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build subsets and save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       699      361      338         248      145      103\n",
      "Val         107       49       58          36       18       18\n",
      "Test        163       65       98          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 14:24:54 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:24:09.617346\n",
      "Validation dataset..\n",
      "Time elapsed: 0:27:57.935494\n",
      "Holdout dataset..\n",
      "Runtime: 0:33:48.587732\n",
      "(699, 96, 114, 96)\n",
      "(107, 96, 114, 96)\n",
      "(163, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 1\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       698      358      340         248      145      103\n",
      "Val          95       40       55          36       18       18\n",
      "Test        176       77       99          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 15:13:52 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:26:31.668863\n",
      "Validation dataset..\n",
      "Time elapsed: 0:30:13.736758\n",
      "Holdout dataset..\n",
      "Runtime: 0:37:10.080518\n",
      "(698, 96, 114, 96)\n",
      "(95, 96, 114, 96)\n",
      "(176, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 2\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       690      351      339         248      145      103\n",
      "Val         101       46       55          36       18       18\n",
      "Test        178       78      100          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 16:07:26 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:26:38.539248\n",
      "Validation dataset..\n",
      "Time elapsed: 0:30:31.001692\n",
      "Holdout dataset..\n",
      "Runtime: 0:37:10.716938\n",
      "(690, 96, 114, 96)\n",
      "(101, 96, 114, 96)\n",
      "(178, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 3\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       708      367      341         248      145      103\n",
      "Val          98       38       60          36       18       18\n",
      "Test        163       70       93          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 16:59:20 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:26:00.405947\n",
      "Validation dataset..\n",
      "Time elapsed: 0:29:43.984154\n",
      "Holdout dataset..\n",
      "Runtime: 0:36:02.778212\n",
      "(708, 96, 114, 96)\n",
      "(98, 96, 114, 96)\n",
      "(163, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 4\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       696      355      341         248      145      103\n",
      "Val         104       47       57          36       18       18\n",
      "Test        169       73       96          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 17:50:36 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:26:39.917821\n",
      "Validation dataset..\n",
      "Time elapsed: 0:30:37.499037\n",
      "Holdout dataset..\n",
      "Runtime: 0:37:00.980550\n",
      "(696, 96, 114, 96)\n",
      "(104, 96, 114, 96)\n",
      "(169, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 5\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       684      353      331         248      145      103\n",
      "Val         115       49       66          36       18       18\n",
      "Test        170       73       97          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 18:41:41 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:22:34.243441\n",
      "Validation dataset..\n",
      "Time elapsed: 0:26:27.746484\n",
      "Holdout dataset..\n",
      "Runtime: 0:32:07.748081\n",
      "(684, 96, 114, 96)\n",
      "(115, 96, 114, 96)\n",
      "(170, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 6\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       708      367      341         248      145      103\n",
      "Val         103       40       63          36       18       18\n",
      "Test        158       68       90          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 19:26:29 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:23:50.473917\n",
      "Validation dataset..\n",
      "Time elapsed: 0:27:18.565841\n",
      "Holdout dataset..\n",
      "Runtime: 0:32:36.140561\n",
      "(708, 96, 114, 96)\n",
      "(103, 96, 114, 96)\n",
      "(158, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 7\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       702      359      343         248      145      103\n",
      "Val          94       42       52          36       18       18\n",
      "Test        173       74       99          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 20:11:11 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:23:05.277569\n",
      "Validation dataset..\n",
      "Time elapsed: 0:26:13.357780\n",
      "Holdout dataset..\n",
      "Runtime: 0:31:57.157007\n",
      "(702, 96, 114, 96)\n",
      "(94, 96, 114, 96)\n",
      "(173, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 8\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       692      357      335         248      145      103\n",
      "Val          99       39       60          36       18       18\n",
      "Test        178       79       99          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 20:55:54 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:22:48.497563\n",
      "Validation dataset..\n",
      "Time elapsed: 0:26:06.431373\n",
      "Holdout dataset..\n",
      "Runtime: 0:32:07.642254\n",
      "(692, 96, 114, 96)\n",
      "(99, 96, 114, 96)\n",
      "(178, 96, 114, 96)\n",
      "Storing data sets\n",
      "Iteration 9\n",
      "         Images    -> AD    -> CN    Patients    -> AD    -> CN\n",
      "-----  --------  -------  -------  ----------  -------  -------\n",
      "All         969      475      494         344      193      151\n",
      "Train       689      352      337         248      145      103\n",
      "Val         112       51       61          36       18       18\n",
      "Test        168       72       96          60       30       30\n",
      "\n",
      "Starting at Thu Jan  7 21:40:54 2021\n",
      "Train dataset..\n",
      "Time elapsed: 0:23:31.408716\n",
      "Validation dataset..\n",
      "Time elapsed: 0:27:17.130046\n",
      "Holdout dataset..\n",
      "Runtime: 0:32:51.808302\n",
      "(689, 96, 114, 96)\n",
      "(112, 96, 114, 96)\n",
      "(168, 96, 114, 96)\n",
      "Storing data sets\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(random_states):\n",
    "    print(f\"Iteration {i}\")\n",
    "    # Patient-wise train-test-split.\n",
    "    # Select a number of subjects for each class, put all their images in the test set \n",
    "    # and all other images in the train set. This is the split that is used in the paper to produce the heatmaps.\n",
    "    test_subjects_per_class = 30\n",
    "    val_subjects_per_class = 18\n",
    "\n",
    "    subjects_AD = df[df['DX'] == 'Dementia']['PTID'].unique()\n",
    "    subjects_CN = df[df['DX'] == 'CN']['PTID'].unique()\n",
    "    subjects_CN = [p for p in subjects_CN if p not in subjects_AD]  # subjects that have both a CN and an AD scan should belong to the AD group\n",
    "\n",
    "    subjects_AD_train, subjects_AD_test = train_test_split(subjects_AD, test_size=test_subjects_per_class, random_state=r)\n",
    "    subjects_AD_train, subjects_AD_val = train_test_split(subjects_AD_train, test_size=val_subjects_per_class, random_state=r)\n",
    "    subjects_CN_train, subjects_CN_test = train_test_split(subjects_CN, test_size=test_subjects_per_class, random_state=r)\n",
    "    subjects_CN_train, subjects_CN_val = train_test_split(subjects_CN_train, test_size=val_subjects_per_class, random_state=r)\n",
    "\n",
    "    subjects_train = np.concatenate([subjects_AD_train, subjects_CN_train])\n",
    "    subjects_val = np.concatenate([subjects_AD_val, subjects_CN_val])\n",
    "    subjects_test = np.concatenate([subjects_AD_test, subjects_CN_test])\n",
    "\n",
    "    # Compile train and val dfs based on subjects.\n",
    "    df_train = df[df.apply(lambda row: row['PTID'] in subjects_train, axis=1)]\n",
    "    df_val = df[df.apply(lambda row: row['PTID'] in subjects_val, axis=1)]\n",
    "    df_test = df[df.apply(lambda row: row['PTID'] in subjects_test, axis=1)]\n",
    "\n",
    "    print_df_stats(df, df_train, df_val, df_test)\n",
    "    \n",
    "    print(\"Starting at \" + time.ctime())\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"Train dataset..\")\n",
    "    train_dataset, train_labels = create_dataset(df_train, z_factor=settings[\"z_factor\"], settings=settings, mask=mask)\n",
    "    print(\"Time elapsed: \" + str(datetime.timedelta(seconds=(time.time()-start))))\n",
    "    print(\"Validation dataset..\")\n",
    "    val_dataset, val_labels = create_dataset(df_val, z_factor=settings[\"z_factor\"], settings=settings, mask=mask)\n",
    "    print(\"Time elapsed: \" + str(datetime.timedelta(seconds=(time.time()-start))))\n",
    "    print(\"Holdout dataset..\")\n",
    "    holdout_dataset, holdout_labels = create_dataset(df_test, z_factor=settings[\"z_factor\"], settings=settings, mask=mask)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Runtime: \" + str(datetime.timedelta(seconds=(end-start))))\n",
    "\n",
    "    print(train_dataset.shape)\n",
    "    print(val_dataset.shape)\n",
    "    print(holdout_dataset.shape)\n",
    "\n",
    "    if save:\n",
    "        print(\"Storing data sets\")\n",
    "        h5 = h5py.File(settings[\"train_h5\"]+str(r)+\".h5\", 'w')\n",
    "        h5.create_dataset('X', data=train_dataset, compression='gzip', compression_opts=9)\n",
    "        h5.create_dataset('y', data=train_labels, compression='gzip', compression_opts=9)\n",
    "        h5.close()\n",
    "        \n",
    "        h5 = h5py.File(settings[\"val_h5\"]+str(r)+\".h5\", 'w')\n",
    "        h5.create_dataset('X', data=val_dataset, compression='gzip', compression_opts=9)\n",
    "        h5.create_dataset('y', data=val_labels, compression='gzip', compression_opts=9)\n",
    "        h5.close()\n",
    "        \n",
    "        h5 = h5py.File(settings[\"holdout_h5\"]+str(r)+\".h5\", 'w')\n",
    "        h5.create_dataset('X', data=holdout_dataset, compression='gzip', compression_opts=9)\n",
    "        h5.create_dataset('y', data=holdout_labels, compression='gzip', compression_opts=9)\n",
    "        h5.close()\n",
    "        \n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mort1)",
   "language": "python",
   "name": "mort1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
